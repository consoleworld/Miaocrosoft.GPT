@page "/"
@using Azure.AI.OpenAI;
@using Azure;
@inject OpenAIClient client;
@inject Miaocrosoft.GPT.Data.ChatHistoryStorage chatHistoryStorage;

<PageTitle>@Current?.FirstOrDefault()?.Content</PageTitle>

<h1>Hello my private ChatGPT</h1>

<table>
    <tbody>
        @if (Current != null)
        {

            @foreach (var item in Current)
            {
                <tr>
                    <td class="align-top">@item.Role:</td>
                    <td>@((MarkupString)item.Content?.Replace(Environment.NewLine, "<br/>"))</td>
                </tr>
            }
        }
        @if (ChatMessageStreaming.Any())
        {
            <tr>
                <td class="align-top">@ChatMessageStreaming.FirstOrDefault()?.Role:</td>
                <td>
                    @foreach (var item in ChatMessageStreaming)
                    {
                        @((MarkupString)item.Content?.Replace(Environment.NewLine, "<br/>"))
                    }
                </td>
            </tr>
        }
        @if (Loading)
        {
            <tr>
                <td colspan="2">Loading...</td>
            </tr>
        }
    </tbody>
</table>
<form class="input-group input-group-lg navbar-fixed-bottom" @onsubmit="Submit">
    <input type="text" class="form-control" aria-label="Sizing example input" placeholder="Here to chat with GPT"
        aria-describedby="inputGroup-sizing-lg" @bind="ChatMessageInput">
</form>
@code {
    protected List<ChatMessage> Current { get; set; }

    private List<ChatMessage> ChatMessageStreaming = new List<ChatMessage>();
    private bool Loading = false;
    public string ChatMessageInput { get; set; } = string.Empty;

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            await chatHistoryStorage.LoadHistory();
            Current = await chatHistoryStorage.GetCurrent();
            StateHasChanged();
        }
    }

    private async Task GetChatCompletions()
    {
        var chatCompletionsOptions = new ChatCompletionsOptions();
        Current.ForEach(chatCompletionsOptions.Messages.Add);
        Response<StreamingChatCompletions> response;
        try
        {
            CancellationTokenSource cancellationTokenSource = new CancellationTokenSource();
            Loading = true;
            response = await client.GetChatCompletionsStreamingAsync(deploymentOrModelName:
            "gpt-3.5-turbo", chatCompletionsOptions);
            using StreamingChatCompletions streamingChatCompletions = response.Value;
            await foreach (StreamingChatChoice choice in streamingChatCompletions.GetChoicesStreaming())
            {
                await foreach (ChatMessage message in choice.GetMessageStreaming())
                {
                    Console.Write(message.Content);
                    await Task.Delay(1);
                    ChatMessageStreaming.Add(message);
                    StateHasChanged();
                }

                if (ChatMessageStreaming.Any())
                {
                    Current.Add(new ChatMessage(ChatMessageStreaming.First().Role, string.Join(string.Empty, ChatMessageStreaming.Select(m
                    => m.Content))));
                    ChatMessageStreaming.Clear();
                    StateHasChanged();
                }
            }
        }
        catch (Exception e)
        {
            Console.WriteLine(e.Message);
        }
        finally
        {
            Loading = false;
            StateHasChanged();
        }
    }

    public async Task Submit()
    {
        if (string.IsNullOrEmpty(ChatMessageInput))
        {
            return;
        }
        Current.Add(new ChatMessage(ChatRole.User, ChatMessageInput));
        ChatMessageInput = string.Empty;
        await GetChatCompletions();
        await chatHistoryStorage.SaveChangeOnCurrentAsync();
    }
}
